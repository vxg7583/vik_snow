{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "r3yowkbgkudgdmi6vgjd",
   "authorId": "1498931345808",
   "authorName": "VIKRANT06",
   "authorEmail": "vikrant.gawde@snowflake.com",
   "sessionId": "1f676764-196c-4f70-8a58-94aa0520594c",
   "lastEditTime": 1755708716466
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "219c2d60-01ff-457b-a0c8-82125f56752c",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "# Import Snowpark session and types\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.types import StructType, StructField, StringType, IntegerType\n\n# Create a Snowpark Session object (replace with your connection details)\n# In a Python worksheet, this is handled automatically with get_active_session()\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# def main(session: snowpark.Session):\n# 1. Create a Snowpark DataFrame with dummy data\ndata_to_write = [\n    (\"user1\", 101, \"A\"),\n    (\"user2\", 102, \"B\"),\n    (\"user3\", 103, \"C\")\n]\nschema = StructType([\n    StructField(\"USER_ID\", StringType()),\n    StructField(\"PRODUCT_ID\", IntegerType()),\n    StructField(\"GRADE\", StringType())\n])\n\ndf = session.create_dataframe(data_to_write, schema)\n\n# 2. Define the internal stage path\n# Use the format: @<database>.<schema>.<stage_name>\nstage_path = \"@capstone2024.capstoneschema2024.capstoneschema2024\"\n\n# 3. Write the DataFrame to the internal stage as a CSV file\n# The .csv() method internally calls COPY INTO <location>\n# The 'header' option adds column names to the file\n# The 'overwrite' option ensures a fresh file is created each time\ndf.write.copy_into_location(\n    location=stage_path,\n    file_format_type=\"csv\",\n    format_type_options={\"COMPRESSION\": \"GZIP\"}, # Optional compression\n    header=True,\n    overwrite=True\n)\n\n# 4. Verify the file was written\n# List the files in the stage to confirm the operation\nresult_df = session.sql(f\"LS {stage_path}\").collect()\n\n# Check for the written file and return a success message\nfile_name = f\"data_0_0_0.csv.gz\" # Default file name format for a single-file unload\n\nif any(row[0].split('/')[-1] == file_name for row in result_df):    \n    print(f\"Success! CSV file written to stage: {stage_path}\")\nelse:\n    print(f\"Error: File not found in stage.\")\n\n# To run this code outside of a Snowpark Python Worksheet, you'd need to create a session first.\n# For example:\n# session = Session.builder.configs(connection_parameters).create()\n# print(main(session))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9b50346b-e6fe-4d73-9661-6dc174535e32",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import snowflake.snowpark as snp\nimport pandas as pd\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Assume 'session' is an active Snowpark session\n# Assume 'snowpark_df' is an existing Snowpark DataFrame\n\n# Example: Create a sample Snowpark DataFrame for demonstration\ndata = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\nschema = [\"Name\", \"ID\"]\nsnowpark_df = session.create_dataframe(data, schema)\n\n# Convert the Snowpark DataFrame to a pandas DataFrame\npandas_df = snowpark_df.to_pandas()\n\n# Now 'pandas_df' is a native pandas DataFrame that can be used for local operations\npandas_df.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58d76d03-9089-4a0c-ad3f-760b2cfa57c7",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nUSE DATABASE CAPSTONE2024;\nUSE SCHEMA CAPSTONESCHEMA2024;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8b6e2cb-75df-484e-898d-e86177ce02c5",
   "metadata": {
    "language": "python",
    "name": "cell6",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "stage_path = '@CAPSTONE2024.CAPSTONESCHEMA2024.CAPSTONESCHEMA2024'\nprint(stage_path)\npandas_df.to_csv(stage_path, index=False) ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b351eccd-c14a-4e68-9c1f-8bdafd9a097d",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "'@\"CAPSTONE2024\".\"CAPSTONESCHEMA2024\".\"CAPSTONESCHEMA2024\"/MLJOB_29CC601B_444E_4711_B866_D3C175EE9459/func.py'",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed715765-4311-4ae5-a02f-2f2c7b501df0",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "LIST @CAPSTONESCHEMA2024;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- Welcome to Snowflake Notebooks!\n-- Try out a SQL cell to generate some data.\nSELECT 'FRIDAY' as SNOWDAY, 0.2 as CHANCE_OF_SNOW\nUNION ALL\nSELECT 'SATURDAY',0.5\nUNION ALL \nSELECT 'SUNDAY', 0.9;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\nmy_df = cell2.to_pandas()\n\n# Chart the data\nst.subheader(\"Chance of SNOW ‚ùÑÔ∏è\")\nst.line_chart(my_df, x='SNOWDAY', y='CHANCE_OF_SNOW')\n\n# Give it a go!\nst.subheader(\"Try it out yourself and show off your skills ü•á\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a93c2866-a3e9-42fd-9bb7-a3feec0daeda",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "users tableau prep - future state \nexcel files \nchristie lendi \ninternal training env: \n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6bf7a0c-28fd-4fb1-ba1e-b39ccbb817cd",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}